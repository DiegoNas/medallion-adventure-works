# Medallion Architecture â€“ Adventure Works (Azure SQL â†’ Databricks Lakehouse)

## VisÃ£o Geral
Este projeto demonstra a construÃ§Ã£o de um pipeline de dados moderno utilizando
a **arquitetura Medallion (Bronze, Silver e Gold)**, com dados do banco
**Adventure Works (Azure SQL)**, processados e persistidos em **Delta Lake** no Databricks.

O objetivo Ã© simular um cenÃ¡rio real de engenharia de dados,
desde a ingestÃ£o de dados operacionais atÃ© a disponibilizaÃ§Ã£o de dados analÃ­ticos
prontos para consumo por ferramentas de BI como Power BI.

---

## ğŸ—ï¸ Arquitetura Geral

**Fonte**
- Azure SQL Database (Adventure Works â€“ OLTP)

**Plataforma**
- Databricks Lakehouse
- Delta Lake
- Unity Catalog / External Catalog
- Delta Live Tables (versÃ£o alternativa do pipeline)

**Camadas**
- Bronze â†’ dados brutos
- Silver â†’ dados tratados e validados
- Gold â†’ modelo analÃ­tico (Star Schema)

---

## ğŸ¥‰ Bronze â€“ IngestÃ£o de Dados

### Objetivo
A camada Bronze Ã© responsÃ¡vel pela **ingestÃ£o inicial dos dados**, preservando:
- esquema original
- tipos de dados
- histÃ³rico
- rastreabilidade

Nenhuma transformaÃ§Ã£o de negÃ³cio Ã© aplicada nesta etapa.

### O que Ã© feito
- Leitura dos dados via **External Catalog (Azure SQL)**
- Carga full das tabelas de origem
- PersistÃªncia em **Delta Lake**
- InclusÃ£o de metadados tÃ©cnicos:
  - `_ingestion_timestamp`
  - `_source_system`
  - `_load_type`

### CaracterÃ­sticas
- Dados brutos
- Alta fidelidade Ã  fonte
- Base para ingestÃµes incrementais futuras

---

## ğŸ¥ˆ Silver â€“ Tratamento e Qualidade dos Dados

### Objetivo
A camada Silver prepara os dados para consumo analÃ­tico, aplicando:
- limpeza
- padronizaÃ§Ã£o
- regras de negÃ³cio bÃ¡sicas
- controle de qualidade

### O que Ã© feito
- DeduplicaÃ§Ã£o de registros (uso de `ROW_NUMBER`)
- PadronizaÃ§Ã£o de colunas e tipos
- ConversÃ£o de datas e valores
- ValidaÃ§Ãµes de integridade
- Garantia de consistÃªncia entre entidades

### Exemplos
- DimensÃµes como **Product** e **Customer**
- Tabelas transacionais como **Sales Order**

---

## ğŸ¥‡ Gold â€“ Modelagem AnalÃ­tica

### Objetivo
A camada Gold entrega dados prontos para anÃ¡lise, modelados em
**Star Schema**, focando em:
- desempenho
- simplicidade
- escalabilidade

### O que Ã© feito
- CriaÃ§Ã£o de tabelas dimensÃ£o
- CriaÃ§Ã£o de tabelas fato
- Relacionamentos analÃ­ticos
- OtimizaÃ§Ã£o para ferramentas de BI

### Consumo
- Power BI
- Consultas SQL analÃ­ticas
- Dashboards executivos

---

## ğŸ”„ Abordagens Implementadas

Este projeto apresenta **duas abordagens vÃ¡lidas** de engenharia de dados:

### 1ï¸âƒ£ Pipeline com SQL / PySpark
- Controle total do fluxo
- Ideal para cenÃ¡rios customizados
- FÃ¡cil depuraÃ§Ã£o

### 2ï¸âƒ£ Delta Live Tables (DLT)
- Pipeline declarativo
- Controle automÃ¡tico de dependÃªncias
- VisualizaÃ§Ã£o grÃ¡fica do fluxo
- Ideal para ambientes produtivos modernos

---

## ğŸ“ˆ Boas PrÃ¡ticas Aplicadas
- Arquitetura Medallion
- Delta Lake
- Versionamento de dados
- SeparaÃ§Ã£o clara de responsabilidades
- PreparaÃ§Ã£o para ingestÃ£o incremental
- Pronto para otimizaÃ§Ãµes (OPTIMIZE, Z-ORDER, Materialized Views)

---

## ğŸ¯ Objetivo do Projeto
Este projeto foi desenvolvido com foco em:
- PortfÃ³lio de Engenharia de Dados
- SimulaÃ§Ã£o de ambientes corporativos reais
- ConsolidaÃ§Ã£o de conceitos modernos de Lakehouse
- PreparaÃ§Ã£o para pipelines produtivos em Databricks, Azure e AWS

---

## ğŸš€ PrÃ³ximos Passos (EvoluÃ§Ãµes)
- IngestÃ£o incremental completa
- ValidaÃ§Ãµes de qualidade automatizadas
- Materialized Views
- ExposiÃ§Ã£o via Power BI
- OrquestraÃ§Ã£o e versionamento de pipelines

